{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Clustering algorithms are not guided by any foreknowledge, so it is described as unsupervised machine learning.\n",
    "- \"Clustering is a useful technique when you want to learn about the structure of a data set but you do not know ahead of time its constituent parts\".\n",
    "\n",
    "# Preliminaries\n",
    "\n",
    "- __pstdev()__ finds the standard deviation of a population, and __stdev()__, finds the stardard deviation of a sample.\n",
    "\n",
    "Our __zscores()__ function converts a sequence (list, tuples, string etc) of floats into z-scores, relative to all the numbers in the sequence.\n",
    "\n",
    "We will create a file called __kmeans.py__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' to go into kmeans.py\n",
    "from __future__ import annotations\n",
    "from typing import TypeVar, Generic, List, Sequence\n",
    "from copy import deepcopy\n",
    "from functools import partial\n",
    "from random import uniform\n",
    "from statistics import mean, pstdev\n",
    "from dataclasses import dataclass\n",
    "\n",
    "# data_point.py to be defined\n",
    "from data_point import DataPoint\n",
    "\n",
    "def zscores(original: Sequence[float]) ->List[float]:\n",
    "    avg: float = mean(original)\n",
    "    std: float = pstdev(original)\n",
    "    if std == 0: # return all zeros if ther is no variation\n",
    "        return[0] * len(original)\n",
    "    return [(x - avg) / std for x in original]\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create a class called __DataPoint__ and save it in a file called __data_point.py__.\n",
    "\n",
    "- The reason why we have two tuples, __._ originals__ and __.dimensions__ is because we later want to replace the dimensions with z-scores by k-means.\n",
    "- The list comprehension on the zip object works inside a function.\n",
    "- Euclidean distance is an extension to the Pythagoras' theorem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' to go into data_point.py\n",
    "from __future__ import annotations\n",
    "from typing import Iterator, Tuple, List, Iterable\n",
    "from math import sqrt\n",
    "\n",
    "\n",
    "class DataPoint:\n",
    "    def __init__(self, initial: Iterable[float]) -> None:\n",
    "        self._originals: Tuple[float, ...] = tuple(initial)\n",
    "        self.dimensions: Tuple[float, ...] = tuple(initial)\n",
    "\n",
    "    @property\n",
    "    def num_dimensions(self) -> int:\n",
    "        return len(self.dimensions)\n",
    "    \n",
    "    # Euclidean distance\n",
    "    def distance(self, other: DataPoint) -> float:\n",
    "        combined: Iterator[Tuple[float, float]] = zip(self.dimensions, other.dimensions)\n",
    "        differences: List[float] = [(x - y) ** 2 for x, y in combined]\n",
    "        return sqrt(sum(differences))\n",
    "\n",
    "    def __eq__(self, other: object) -> bool:\n",
    "        if not isinstance(other, DataPoint):\n",
    "            return NotImplemented\n",
    "        return self.dimensions == other.dimensions\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return self._originals.__repr__()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The k-means clustering algorithm\n",
    "\n",
    "\"K-means is a clustering algorithm that attempts to group data points into a certain predefined number of clusters, based on each point’s relative distance to the center of the cluster. In every round of k-means, the distance between every data point and every center of a cluster (a point known as a centroid) is calculated. Points are assigned to the cluster whose centroid they are closest to. Then the algorithm recalculates all of the centroids, finding the mean of each cluster’s assigned points and replacing the old centroid with the new mean. The process of assigning points and recalculating centroids continues until the centroids stop moving or a certain number of iterations occurs. \"\n",
    "\n",
    "- To make the spread of points more even, we normalise the data by calculating each value's z-score relative to other values of the same type.\n",
    "\n",
    "The steps of the algorithm:\n",
    "\n",
    "1. Initialise all the data points and decide on how many clusters we want.\n",
    "2. Normalise all the data points.\n",
    "3. Create random centroids associated with each cluster.\n",
    "4. Assign each data point to the cluster of the centroid it is closest to.\n",
    "5. Recalculate each centroid so it is the centre (mean) of the cluster it is associated with.\n",
    "6. Repeat steps 4 and 5 until a maximum number of iterations is reached or the centroids stop moving (convergence).\n",
    "\n",
    "We will have a class for maintaining the state and running the algorithm - __KMeans__.\n",
    "\n",
    "-__KMeans__  is a generic class that works with any __DataPoint__ or any subclass of __DataPoint__, as defined by the __Point__ type's __bound__. It has an internal class __Cluster__ that keeps track of the individual clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''to go into kmeans.py\n",
    "from __future__ import annotations\n",
    "from typing import TypeVar, Generic, List, Sequence\n",
    "from copy import deepcopy\n",
    "from functools import partial\n",
    "from random import uniform\n",
    "from statistics import mean, pstdev\n",
    "from dataclasses import dataclass\n",
    "from data_point import DataPoint\n",
    "\n",
    "\n",
    "def zscores(original: Sequence[float]) -> List[float]:\n",
    "    avg: float = mean(original)\n",
    "    std: float = pstdev(original)\n",
    "    if std == 0:  # return all zeros if ther is no variation\n",
    "        return [0] * len(original)\n",
    "    return [(x - avg) / std for x in original]\n",
    "\n",
    "\n",
    "Point = TypeVar(\"Point\", bound=DataPoint)\n",
    "\n",
    "\n",
    "class KMeans(Generic[Point]):\n",
    "    @dataclass\n",
    "    class Cluster:\n",
    "        points: List[Point]\n",
    "        centroid: DataPoint\n",
    "\n",
    "    def __init__(self, k: int, points: List[Point]) -> None:\n",
    "        if k < 1:  # k-means can't do negative or zero clusters\n",
    "            raise ValueError\n",
    "        self._points: List[Point] = points\n",
    "        self._zscore_normalize()  # defined below\n",
    "        # initialise empty clusters with random centroids\n",
    "        self._clusters: List[KMeans.Cluster] = []\n",
    "        for _ in range(k):\n",
    "            rand_point: DataPoint = self._random_point()  # defined below\n",
    "            # assign centroid to a Cluster class variable\n",
    "            cluster: KMeans.Cluster = KMeans.Cluster([], rand_point)\n",
    "            # add to ._clusters list\n",
    "            self._clusters.append(cluster)\n",
    "\n",
    "    @property\n",
    "    def _centroids(self) -> List[DataPoint]:\n",
    "        return [x.centroid for x in self._clusters]\n",
    "\n",
    "    # a method that returns a list of values of one dimension/field of\n",
    "    # every datapoint\n",
    "    def _dimension_slice(self, dimension: int) -> List[float]:\n",
    "        return [x.dimensions[dimension] for x in self._points]\n",
    "\n",
    "    #  method to replace the values in dimensions with their z-scores\n",
    "    #  equivalent\n",
    "    def _zscore_normalize(self) -> None:\n",
    "        # create temp list zscored\n",
    "        zscored: List[List[float]] = [[] for _ in range(len(self._points))]\n",
    "        # .num_dimensions is a property of DataPoint class\n",
    "        for dimension in range(self._points[0].num_dimensions):\n",
    "            # get the list of values for the dimension\n",
    "            dimension_slice: List[float] = self._dimension_slice(dimension)\n",
    "            for index, zscore in enumerate(zscores(dimension_slice)):\n",
    "                zscored[index].append(zscore)\n",
    "        for i in range(len(self._points)):\n",
    "            # update the .dimensions part of each datapoint with\n",
    "            # values in zscored\n",
    "            self._points[i].dimensions = tuple(zscored[i])\n",
    "\n",
    "    def _random_point(self) -> DataPoint:\n",
    "        # empty list to hold the dimensions of the random point, which\n",
    "        # this method will return\n",
    "        rand_dimensions: List[float] = []\n",
    "        # .num_dimensions is a property of DataPoint class\n",
    "        for dimension in range(self._points[0].num_dimensions):\n",
    "            # get the list of values for the dimension\n",
    "            values: List[float] = self._dimension_slice(dimension)\n",
    "            # calculate a random value that's within the bound of values\n",
    "            rand_value: float = uniform(min(values), max(values))\n",
    "            rand_dimensions.append(rand_value)\n",
    "        return DataPoint(rand_dimensions)\n",
    "\n",
    "    # Find the closest cluster centroid to each point and assign the point to\n",
    "    # that cluster\n",
    "    def _assign_clusters(self) -> None:\n",
    "        for point in self._points:\n",
    "            # partial() takes a function and provides it with some of its parameters\n",
    "            #  before the function is applied. In this case, we supply the\n",
    "            # DataPoint.distance() method with the point we are calculating from as\n",
    "            # its other parameter. This will result in each centroid’s distance to\n",
    "            # the point being computed and the lowest-distance centroid’s being returned by min().\n",
    "            closest: DataPoint = min(\n",
    "                self._centroids, key=partial(DataPoint.distance, point)\n",
    "            )\n",
    "            idx: int = self._centroids.index(closest)\n",
    "            cluster: KMeans.Cluster = self._clusters[idx]\n",
    "            cluster.points.append(point)\n",
    "\n",
    "    def _generate_centroids(self) -> None:\n",
    "        for cluster in self._clusters:\n",
    "            if len(cluster.points) == 0:  # keep the same centroid if no points\n",
    "                continue\n",
    "            means: List[float] = []\n",
    "            for dimension in range(cluster.points[0].num_dimensions):\n",
    "                dimension_slice: List[float] = [\n",
    "                    p.dimensions[dimension] for p in cluster.points\n",
    "                ]\n",
    "                # add the mean of a particular dimension to the means list\n",
    "                means.append(mean(dimension_slice))\n",
    "            # the means list is now new centroid of the cluster\n",
    "            cluster.centroid = DataPoint(means)\n",
    "\n",
    "    def run(self, max_iterations: int = 100) -> List(KMeans.Cluster):\n",
    "        for iteration in range(max_iterations):\n",
    "            for cluster in self._clusters:\n",
    "                # clear all clusters, KMeans.Cluster.points is a list - can use .clear()\n",
    "                cluster.points.clear()\n",
    "            self._assign_clusters()  # find cluster each point is closest to\n",
    "            old_centroids: List[DataPoint] = deepcopy(self._centroids)  # record\n",
    "            self._generate_centroids()  # find new centroids\n",
    "            if old_centroids == self._centroids:  # have centroids moved?\n",
    "                print(f\"Converged after {iteration} iterations\")\n",
    "                return self._clusters\n",
    "        return self._clusters\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    point1: DataPoint = DataPoint([2.0, 1.0, 1.0])\n",
    "    point2: DataPoint = DataPoint([2.0, 2.0, 5.0])\n",
    "    point3: DataPoint = DataPoint([3.0, 1.5, 2.5])\n",
    "    kmeans_test: KMeans[DataPoint] = KMeans(2, [point1, point2, point3])\n",
    "    test_clusters: List[KMeans.Cluster] = kmeans_test.run()\n",
    "    for index, cluster in enumerate(test_clusters):\n",
    "        print(f\"Cluster {index}: {cluster.points}\")\n",
    "\"\"\"\n",
    "Expected Output:\n",
    "\n",
    "Converged after 1 iterations\n",
    "Cluster 0: [(2.0, 1.0, 1.0), (3.0, 1.5, 2.5)]\n",
    "Cluster 1: [(2.0, 2.0, 5.0)]\n",
    "\"\"\"\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
