{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalising Data\n",
    "We want to feature scale our data to values between 0 and 1\n",
    "\n",
    "To go into util.py:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# assume all rows are of the same length\n",
    "# and feature scale each column to be in the range 0 to 1\n",
    "def normalize_by_feature_scaling(dataset: List[List[float]]) -> None:\n",
    "    for col_num in range(len(dataset[0])):\n",
    "        column: List[float] = [row[col_num] for row in dataset]\n",
    "        maximum = max(column)\n",
    "        minimum = min(column)\n",
    "        for row_num in range(len(dataset)):\n",
    "            dataset[row_num][col_num] = (dataset[row_num][col_num] - minimum) / (\n",
    "                maximum - minimum\n",
    "            )\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The classic iris data set\n",
    "\n",
    "- Our neural network will have 3 output neurons, with each representing one possible species. e.g. [0.9, 0.3, 0.1] will represent the classification of iris-setosa, because the first neuron represents that species, and it is the largest number.\n",
    "\n",
    "- The values in iris_classifications will be used to calculate the errors of the neural network outputs after each training step.\n",
    "\n",
    "__\" Warning: The lack of error-checking code makes this code fairly dangerous. It is not suitable for production, but it is fine for testing.\"__\n",
    "\n",
    "Reading the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from typing import List\n",
    "from random import shuffle\n",
    "\n",
    "# from .py files in the same folder\n",
    "from util import normalize_by_feature_scaling\n",
    "from network import Network\n",
    "\n",
    "# initialised some lists to be filled\n",
    "iris_parameters: List[List[float]] = []\n",
    "iris_classifications: List[List[float]] = []\n",
    "iris_species: List[str] = []\n",
    "\n",
    "with open('iris.csv', mode = 'r') as iris_file:\n",
    "    irises: List = list(csv.reader(iris_file))\n",
    "    shuffle(irises) # get our lines of data in random order\n",
    "    for iris in irises:\n",
    "        # the first columns are the sepal length, sepal width, petal length, and petal width\n",
    "        parameters: List[float] = [float(n) for n in iris[0:4]]\n",
    "        iris_parameters.append(parameters)\n",
    "        # record the species classification\n",
    "        species: str = iris[4]\n",
    "        if species == 'Iris-setosa':\n",
    "            iris_classifications.append([1.0, 0.0, 0.0])\n",
    "        elif species == 'Iris-versicolor':\n",
    "            iris_classifications.append([0.0, 1.0, 0.0])\n",
    "        else:\n",
    "            iris_classifications.append([0.0, 0.0, 1.0])\n",
    "        iris_species.append(species)\n",
    "\n",
    "normalize_by_feature_scaling(iris_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the actual network:\n",
    "- 4 neurons for the input layer - 4 attributes : sepal length, sepal width, petal length, and petal width\n",
    "- 0.3 learning rate\n",
    "- 3 output neurons representing 3 species\n",
    "-  The number of neurons in the hidden layer and the learning rate can be experimented with to improve accuracy/precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_network: Network = Network([4, 6, 3], 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output intepreting function ( for using the validate function in network.py):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iris_interpret_output(output: List[float]) -> str:\n",
    "    if max(output) == output[0]:\n",
    "        return 'Iris-setosa'\n",
    "    elif max(output) == output[1]:\n",
    "        return 'Iris-versicolor'\n",
    "    else:\n",
    "        return 'Iris-virginica'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the first 140 irises out of the 150 irises 50 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train over the first 140 irises in the data set 50 times\n",
    "iris_trainers: List[List[float]] = iris_parameters[0:140]\n",
    "iris_trainers_corrects: List[List[float]] = iris_classifications[0:140]\n",
    "for _ in range(50):\n",
    "    iris_network.train(iris_trainers, iris_trainers_corrects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the network over the last 10 irises:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 correct of 10= 80.0%\n"
     ]
    }
   ],
   "source": [
    "# test over the last 10 of the irises in the data set:\n",
    "iris_testers: List[List[float]] = iris_parameters[140:150]\n",
    "iris_testers_corrects: List[str] = iris_species[140:150]\n",
    "iris_results = iris_network.validate(iris_testers, iris_testers_corrects,\n",
    "                                    iris_interpret_output)\n",
    "\n",
    "# print result\n",
    "print(f'{iris_results[0]} correct of {iris_results[1]}\\\n",
    "= {iris_results[2] * 100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Wine Dataset\n",
    "\n",
    "- In this dataset, there are 13 inputs/attributes and 3 outputs (cultivars of wine).\n",
    "\n",
    "- Interestingly, the network works well with fewer neurons in the hidden layer than in the input layer. It is possible that some of the inputs are not very useful for the purpose of predicting the cultivar. Note that this is not exactly how having fewer neurons in a hidden layer work though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_parameters: List[List[float]] = []\n",
    "wine_classifications: List[List[float]] = []\n",
    "wine_species: List[int] = []\n",
    "    \n",
    "with open('wine.csv', mode='r') as wine_file:\n",
    "    wines: List = list(csv.reader(wine_file, quoting=csv.QUOTE_NONNUMERIC))\n",
    "    shuffle(wines) # get our lines of data in random order\n",
    "    for wine in wines:\n",
    "        # classification is in first column this time\n",
    "        parameters: List[float] = [float(n) for n in wine[1:14]]\n",
    "        wine_parameters.append(parameters)\n",
    "        species: int = int(wine[0])\n",
    "        if species == 1:\n",
    "            wine_classifications.append([1.0, 0.0, 0.0])\n",
    "        elif species == 2:\n",
    "            wine_classifications.append([0.0, 1.0, 0.0])\n",
    "        else:\n",
    "            wine_classifications.append([0.0, 0.0, 1.0])\n",
    "        wine_species.append(species)\n",
    "\n",
    "normalize_by_feature_scaling(wine_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_network: Network = Network([13, 7, 3], 0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpreting function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wine_interpret_output(output: List[float]) -> int:\n",
    "    if max(output) == output[0]:\n",
    "        return 1\n",
    "    elif max(output) == output[1]:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training over the first 150 wines 10 times:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train over the first 150 wines 10 times\n",
    "wine_trainers: List[List[float]] = wine_parameters[0:150]\n",
    "wine_trainers_corrects: List[List[float]] = wine_classifications[0:150]\n",
    "\n",
    "for _ in range(10):\n",
    "    wine_network.train(wine_trainers, wine_trainers_corrects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test over the last 28 of the wines in the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 correct of 28 = 92.85714285714286%\n"
     ]
    }
   ],
   "source": [
    "# test over the last 28 of the wines in the data set\n",
    "wine_testers: List[List[float]] = wine_parameters[150:178]\n",
    "wine_testers_corrects: List[int] = wine_species[150:178]\n",
    "\n",
    "wine_results = wine_network.validate(wine_testers, wine_testers_corrects, wine_interpret_output)\n",
    "\n",
    "print(f'{wine_results[0]} correct of {wine_results[1]} = {wine_results[2] * 100}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
